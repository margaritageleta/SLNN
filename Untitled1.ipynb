{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_show(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import line_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = np.random.normal(size = 35, scale = 0.1)[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import line_search\n",
    "#from optinpy.optinpy.linesearch import interp23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ls import linesearch\n",
    "def GM(x, f, g, eps, kmax, precision = 6):\n",
    "    gradient_norm = round(np.linalg.norm(g(x)), precision)\n",
    "    Xk = [[np.NaN, f(x), gradient_norm]]\n",
    "    #==============#\n",
    "    k = 0\n",
    "    almax = 1\n",
    "    while np.linalg.norm(g(x)) > eps and k < kmax:\n",
    "        d = -g(x)\n",
    "        if k != 0:\n",
    "            almax = np.squeeze(2 * (f(x) - f(x_prev)) / (g(x).T @ d))\n",
    "        alpha, iout = linesearch(f, g, x, d, alpham = almax, c1 = 0.01, c2 = 0.45, maxiter = 500, eps = 10e-6)\n",
    "        x_prev = x\n",
    "        x = x + alpha*d\n",
    "        k += 1\n",
    "        #===========#\n",
    "        gradient_norm = np.round(np.linalg.norm(g(x)), precision)\n",
    "        Xk.append([alpha, f(x), gradient_norm])\n",
    "        #===========#\n",
    "        #print(\"[GM] Final:\",x.T)\n",
    "        #print(\"[GM] Iterations:\", k)\n",
    "    data = pd.DataFrame(Xk, columns=[\"alpha\", \"f(x)\", \"||g(x)||\"], dtype=np.float)\n",
    "    return x, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFGS(x, f, g, eps, kmax, precision = 6):\n",
    "    gradient_norm = np.round(np.linalg.norm(g(x)), precision)\n",
    "    Xk = [[np.NaN, f(x), gradient_norm]]\n",
    "\n",
    "    H = I = np.identity(len(g(x)))\n",
    "    k = 0\n",
    "    almax = 1\n",
    "    while np.linalg.norm(g(x)) > eps and k < kmax:\n",
    "        d = -H @ g(x)\n",
    "        if k != 0:\n",
    "            almax = np.squeeze(2 * (f(x) - f(x_prev)) / (g(x).T @ d))\n",
    "            #almax = old_al * ((old_g.T) @ old_d) / (g(x).T @ d)\n",
    "        #alpha, iout = linesearch(f, g, x, d, alpham = almax, c1 = 0.01, c2 = 0.45, maxiter = 50, eps = 10e-6)\n",
    "        if k > 0:\n",
    "            alpha, *_ = line_search(f, g, x, d, old_old_fval=f(x_prev), c1 = 0.01, c2 = 0.45)\n",
    "        else:\n",
    "            alpha, *_ = line_search(f, g, x, d, c1 = 0.01, c2 = 0.45)\n",
    "        if alpha is None:\n",
    "            print(\"Stopped because of alpha (!)\")\n",
    "            return x, pd.DataFrame(Xk, columns=[\"alpha\", \"f(x)\", \"||g(x)||\"], dtype=np.float)\n",
    "        old_g = g(x)\n",
    "        old_d = d\n",
    "        old_al = alpha\n",
    "        x, x_prev = x + alpha*d, x\n",
    "        s = x - x_prev\n",
    "        y = g(x) - g(x_prev)\n",
    "        y = y[None, :]\n",
    "        rho = 1 / ((y).T @ s)\n",
    "        H = (I - rho * s @ y.T) @ H @ (I - rho * y @ (s.T)) + rho * s @ s.T\n",
    "        k += 1\n",
    "        \n",
    "        gradient_norm = np.round(np.linalg.norm(g(x)), precision)\n",
    "        Xk.append([alpha, f(x), gradient_norm])\n",
    "    return x, pd.DataFrame(Xk, columns=[\"alpha\", \"f(x)\", \"||g(x)||\"], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CGM(x, f, g, eps, kmax, iCG, iRC):\n",
    "    d = -g(x)\n",
    "    k = 0\n",
    "    while np.linalg.norm(g(x)) > eps and k < kmax:\n",
    "        alpha, iout = linesearch(f, g, x, d, 50, c1 = 0.01, c2 = 0.45, maxiter = 500, eps = 10e-6)\n",
    "        x, x_prev = x + alpha*d, x\n",
    "        # ============================================================================================================ #  \n",
    "        # CGM variants\n",
    "        if iCG == \"FR\":\n",
    "            beta = (g(x).T @ g(x)) / (g(x_prev).T @ g(x_prev))\n",
    "        elif iCG == \"PR\":\n",
    "            beta = max(0, g(x).T @ (g(x) - g(x_prev)) / (g(x_prev).T @ g(x_prev)))\n",
    "        else:\n",
    "            raise TypeError(\"iCG should be FR (Fletcher-Reeves) or PR (Polak-Ribière)\")\n",
    "        # ============================================================================================================ # \n",
    "        # Restart conditions\n",
    "        if iRC > 0 and nu is None:\n",
    "            raise TypeError(f\"nu is a necessary parameter with iRC equal to {iRC}\")\n",
    "        if (iRC == 1 and k % nu == 0 or\n",
    "                iRC == 2 and g(x).T @ g(x_prev) / np.linalg.norm(g(x))**2 > nu or\n",
    "                k == 0):\n",
    "            d = -g(x)\n",
    "        else:\n",
    "            d = -g(x) + beta*d\n",
    "        # ============================================================================================================ # \n",
    "        k += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y(X, w):\n",
    "    \"\"\"Evaluates a SLNN with weigths `w` \"\"\"\n",
    "\n",
    "    return sigmoid((sigmoid(X) @ w.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_loss(w, X, ytr, p=0):\n",
    "    #return (2 * sigmoid(X) * ((y(X, w) - ytr) * y(X, w) * (1 - y(X, w))) + p*w).sum(axis=0)\n",
    "    return np.squeeze(2 * sigmoid(X.T) @ ((y(X, w) - ytr) * y(X, w) * (1 - y(X, w))) + p*w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_loss(np.full((1, 35), 2), train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_loss(wt, train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opty = BFGS(wt, lambda w: loss(w, train, ytr, 30), lambda w: g_loss(w, train, ytr, 30), 1e-6, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_show(opty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_loss(opty, train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss(opty, train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.round(np.squeeze(y(train, opty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.squeeze(ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(data):\n",
    "    if len(data) < 10:\n",
    "        return data\n",
    "    data_out = data.head(5)\n",
    "    data_out = data_out.append(data.tail(5))\n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize.linesearch import line_search\n",
    "from scipy.optimize.linesearch import line_search_BFGS\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#def nnet(Xtrain, Ytrain, lambd = 0.00, epsilon = 1.0e-06, kmax = 500, BLS_params, optimizer):\n",
    "def nnet(Xtrain, Ytrain, optimizer, epsilon = 1.0e-06, kmax = 500):\n",
    "        ### TRAIN ###\n",
    "        \n",
    "        \n",
    "        \"\"\" init rand weights \"\"\" \n",
    "        ini_weights = np.random.normal(size = 35)[None, :]\n",
    "    \n",
    "        if optimizer == \"GM\": # Steepest descent\n",
    "            \"\"\" train SLNN: \"\"\" \n",
    "            opt_w = GM(ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax)\n",
    "            num_show(opt_w)\n",
    "            print(\"Loss:\", loss(opt_w, Xtrain, Ytrain))\n",
    "            return opt_w\n",
    "\n",
    "        elif optimizer == \"CGM\": # Conjugate Gradient method\n",
    "            opt_w = CGM(ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax, \"FR\", 0)\n",
    "            num_show(opt_w)\n",
    "            print(\"Loss:\", loss(opt_w, Xtrain, Ytrain))\n",
    "\n",
    "        elif optimizer == \"BFGS\": # Quasi-Newton BFGS\n",
    "            opt_w = BFGS(ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax)\n",
    "            #opt_w, min_loss, info = scipy.optimize.fmin_l_bfgs_b(lambda w: loss(w, train, ytr), wt, fprime=(lambda w: g_loss(w, train, ytr)))\n",
    "            num_show(opt_w)\n",
    "            print(\"Loss:\", loss(opt_w, Xtrain, Ytrain))\n",
    "        \n",
    "        else:\n",
    "            print(\"Invalid optimizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnet:\n",
    "    def __init__(self, Xtrain, Ytrain):\n",
    "        self.Xtrain          = Xtrain\n",
    "        self.ini_weights    = np.random.normal(size = 35)[None, :]            \n",
    "        self.Ytrain        = Ytrain\n",
    "        \n",
    "    def accuracy_train(self, tuned_weights):\n",
    "        delta, num_samples = 0, len(self.Ytrain)\n",
    "        for i in range(num_samples):\n",
    "            if abs(np.round(y(self.Xtrain, tuned_weights)[i],2) - self.Ytrain[i]) < 1e-06: delta += 1\n",
    "        accuracy = (100/num_samples)*delta\n",
    "        print(\"Accuracy train: \", accuracy, \"%\")\n",
    "        return accuracy\n",
    "    \n",
    "    def accuracy_test(self, Xtest, Ytest, tuned_weights):\n",
    "        delta, num_samples = 0, len(Ytest)\n",
    "        for i in range(num_samples):\n",
    "            if abs(np.round(y(Xtest, tuned_weights)[i],2) - Ytest[i]) < 1e-06: delta += 1\n",
    "        accuracy = (100/num_samples)*delta\n",
    "        print(\"Accuracy test: \", accuracy, \"%\")\n",
    "        \n",
    "        if nnet.accuracy_train(self, tuned_weights)*0.25 > accuracy:\n",
    "            print(\"Possibly overfitted model!\")\n",
    "        \n",
    "    def train(self, optimizer, epsilon, kmax):\n",
    "        \"\"\" train SLNN: \"\"\" \n",
    "        if optimizer == \"GM\":\n",
    "            tuned_weights = GM(self.ini_weights, lambda w: loss(w, self.Xtrain, self.Ytrain), lambda w: g_loss(w, self.Xtrain, self.Ytrain), epsilon, kmax)\n",
    "        elif optimizer == \"CGM\":\n",
    "            tuned_weights = CGM(self.ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax, \"FR\", 0)\n",
    "        elif optimizer == \"BFGS\":\n",
    "            tuned_weights = BFGS(self.ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax)\n",
    "        else:\n",
    "            print(\"Invalid optimizer.\")\n",
    "            return self.ini_weights\n",
    "        num_show(tuned_weights)\n",
    "        print(\"Loss:\", loss(tuned_weights, self.Xtrain, self.Ytrain))\n",
    "        #nnet.accuracy_train(self, opt_w)\n",
    "        return tuned_weights\n",
    "\n",
    "    def test(self, Xtest, Ytest, tuned_weights):\n",
    "        nnet.accuracy_test(self, Xtest, Ytest, tuned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLNN:\n",
    "    def __init__(self, n = 35):\n",
    "        self.weights    = np.zeros((1, 35))\n",
    "        self._trained = False\n",
    "        self.out = None\n",
    "        \n",
    "    def train(self, optimizer, x, y, p = 0, epsilon=10e-6, kmax = 1000):\n",
    "        if optimizer == \"GM\":\n",
    "            self.weights, self.out = GM(self.weights, lambda w: loss(w, x, y, p), lambda w: g_loss(w, x, y, p), epsilon, kmax)\n",
    "        elif optimizer == \"CGM\":\n",
    "            self.weights, self.out =  CGM(self.weights, lambda w: loss(w, x, y, p), lambda w: g_loss(w, x, y, p), epsilon, kmax, \"FR\", 0), None\n",
    "        elif optimizer == \"BFGS\":\n",
    "            self.weights, self.out = BFGS(self.weights, lambda w: loss(w, x, y, p), lambda w: g_loss(w, x, y, p), epsilon, kmax)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid optimizer.\")\n",
    "        self.x, self.y, self.p = x, y, p\n",
    "        self.optimizer = optimizer\n",
    "        self._trained = True\n",
    "            \n",
    "    def predict(self, x):\n",
    "        return np.round(y(x, self.weights))\n",
    "    \n",
    "    def accuracy(self, x, y):\n",
    "        return 100 * np.sum(self.predict(x) == y) / len(y)\n",
    "    \n",
    "    def summary(self, Xte, yte):\n",
    "        if not self._trained:\n",
    "            print(\"Model is not trained yet\")\n",
    "        else:\n",
    "            print(f\"Single Layer Neural Network (SLNN)\")\n",
    "            print(\"-\"*75)\n",
    "            print(f\"Input size:\\t\\t\\t{len(np.squeeze(self.weights))}\")\n",
    "            print(f\"Output size:\\t\\t\\t1 (binary)\")\n",
    "            print(\"-\"*75)\n",
    "            print(f\"Train data:\\t\\t\\t{len(self.x)} observations\")\n",
    "            print(f\"Chosen optimization routine:\\t{self.optimizer}\")\n",
    "            print(f\"Regularization parameter:\\t{self.p}\")\n",
    "            print(f\"Loss:\\t\\t\\t\\t{loss(self.weights, self.x, self.y, self.p)[0]}\")\n",
    "            print(f\"Training accuracy:\\t\\t{self.accuracy(self.x, self.y)}%\")\n",
    "            print(f\"Test accuracy:\\t\\t\\t{self.accuracy(Xte, yte)}%\")\n",
    "            print(\"-\"*75)\n",
    "            print(\"Gradient: \\n\", g_loss(self.weights, self.x, self.y, self.p))\n",
    "            print(\"-\"*75)\n",
    "            num_show(self.weights)\n",
    "            return print_result(self.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped because of alpha (!)\n",
      "Single Layer Neural Network (SLNN)\n",
      "---------------------------------------------------------------------------\n",
      "Input size:\t\t\t35\n",
      "Output size:\t\t\t1 (binary)\n",
      "---------------------------------------------------------------------------\n",
      "Train data:\t\t\t500 observations\n",
      "Chosen optimization routine:\tBFGS\n",
      "Regularization parameter:\t0\n",
      "Loss:\t\t\t\t117.0073656713344\n",
      "Training accuracy:\t\t94.0%\n",
      "Test accuracy:\t\t\t97.14%\n",
      "---------------------------------------------------------------------------\n",
      "Gradient: \n",
      " [ 0.61998449  3.92520729 -2.44168378  5.62611516  1.46925762  2.89138462\n",
      " -5.86410508 -6.92879206  0.53050093  2.83180276  3.70438245 -0.55934578\n",
      " -5.42501089  1.06392025  4.07823628  1.21244002  1.81519519 -4.75612543\n",
      "  3.05567146  0.97879114  1.54304234 -0.28910289 -5.54642678 -1.57507568\n",
      "  3.64953897  3.11992963  0.47765856 -7.91520477 -0.03049402  2.96472292\n",
      "  1.1763982  -2.80116812 -2.20565258 -1.4407496  -0.11770803]\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>f(x)</th>\n",
       "      <th>||g(x)||</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>21.701217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.873272e-02</td>\n",
       "      <td>121.212609</td>\n",
       "      <td>83.924269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.732532e-10</td>\n",
       "      <td>117.027176</td>\n",
       "      <td>20.973468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.110701e-16</td>\n",
       "      <td>117.007366</td>\n",
       "      <td>20.003704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alpha        f(x)   ||g(x)||\n",
       "0           NaN  125.000000  21.701217\n",
       "1  1.873272e-02  121.212609  83.924269\n",
       "2  7.732532e-10  117.027176  20.973468\n",
       "3  5.110701e-16  117.007366  20.003704"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0.3)\n",
    "net = SLNN()\n",
    "net.train(\"BFGS\", train, ytr)\n",
    "net.summary(test, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnetGM = nnet(train, ytr)\n",
    "tuning = nnetGM.train(\"GM\", 1.0e-06, kmax = 500)\n",
    "nnetGM.test(test, yte, tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnetCGM = nnet(train, ytr)\n",
    "tuning = nnetGM.train(\"CGM\", 1.0e-06, kmax = 500)\n",
    "nnetCGM.test(test, yte, tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnetBFGS = nnet(train, ytr)\n",
    "tuning = nnetGM.train(\"BFGS\", 1.0e-06, kmax = 500)\n",
    "nnetBFGS.test(test, yte, tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "#nnet(train, ytr, \"BFGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnet(train, ytr, \"CGM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1,3,5,7,9], 0.5, 0)\n",
    "nnet(train, ytr, \"GM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [0,2,4,6,8], 0.5, 0)\n",
    "nnet(train, ytr, \"GM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [0,2,4,6,8], 0.5, 0)\n",
    "nnet(train, ytr, \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnet(train, ytr, \"BFGS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MATLAB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mXtr = np.array([\n",
    "    [1, 1, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "]).T\n",
    "mytr = np.array([[0, 0, 1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss(np.array([[2, 2, 2]]), mXtr, mytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
