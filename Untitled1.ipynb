{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_show(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize.linesearch import line_search\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = np.random.normal(size = 35, scale = 0.1)[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = minimize(lambda w: loss(w, train, ytr), wt, method = 'BFGS')\n",
    "opt_w = opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_show(opt_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize.linesearch import line_search_BFGS\n",
    "#from optinpy.optinpy.linesearch import interp23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ls import linesearch\n",
    "def GM(x, f, g, eps, kmax, precision = 6):\n",
    "    gradient_norm = round(np.linalg.norm(g(x)), precision)\n",
    "    Xk = [[np.NaN, f(x), gradient_norm]]\n",
    "    #==============#\n",
    "    k = 0\n",
    "    almax = 1\n",
    "    while np.linalg.norm(g(x)) > eps and k < kmax:\n",
    "        d = -g(x)\n",
    "        if k != 0:\n",
    "            almax = np.squeeze(2 * (f(x) - f(x_prev)) / (g(x).T @ d))\n",
    "        alpha, iout = linesearch(f, g, x, d, alpham = almax, c1 = 0.01, c2 = 0.45, maxiter = 500, eps = 10e-6)\n",
    "        x_prev = x\n",
    "        x = x + alpha*d\n",
    "        k += 1\n",
    "        #===========#\n",
    "        gradient_norm = np.round(np.linalg.norm(g(x)), precision)\n",
    "        Xk.append([alpha, f(x), gradient_norm])\n",
    "        #===========#\n",
    "        #print(\"[GM] Final:\",x.T)\n",
    "        #print(\"[GM] Iterations:\", k)\n",
    "        data = pd.DataFrame(Xk, columns=[\"alpha\", \"f(x)\", \"||g(x)||\"], dtype=np.float)\n",
    "    return [x, data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFGS(x, f, g, eps, kmax):\n",
    "    H = I = np.identity(len(g(x)))\n",
    "    k = 0\n",
    "    almax = 1\n",
    "    while np.linalg.norm(g(x)) > eps and k < kmax:\n",
    "        d = -H @ g(x)\n",
    "        if k != 0:\n",
    "            almax = np.squeeze(2 * (f(x) - f(x_prev)) / (g(x).T @ d))\n",
    "            #almax = old_al * ((old_g.T) @ old_d) / (g(x).T @ d)\n",
    "        print(\"almax: \", almax)\n",
    "        alpha, iout = linesearch(f, g, x, d, alpham = almax, c1 = 0.01, c2 = 0.45, maxiter = 50, eps = 10e-6)\n",
    "        #alpha, *_ = line_search_BFGS(f, lambda x: g(x).T, x, d.T, c1 = 0.01, old_fval=1)\n",
    "        print(\" alpha: \", alpha)\n",
    "        if alpha == 0:\n",
    "            return x\n",
    "        old_g = g(x)\n",
    "        old_d = d\n",
    "        old_al = alpha\n",
    "        x, x_prev = x + alpha*d, x\n",
    "        s = x - x_prev\n",
    "        y = g(x) - g(x_prev)\n",
    "        y = y[None, :]\n",
    "        rho = 1 / ((y).T @ s)\n",
    "        H = (I - rho * s @ y.T) @ H @ (I - rho * y @ (s.T)) + rho * s @ s.T\n",
    "        k += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CGM(x, f, g, eps, kmax, iCG, iRC):\n",
    "    d = -g(x)\n",
    "    k = 0\n",
    "    while np.linalg.norm(g(x)) > eps and k < kmax:\n",
    "        alpha, iout = linesearch(f, g, x, d, 50, c1 = 0.01, c2 = 0.45, maxiter = 500, eps = 10e-6)\n",
    "        x, x_prev = x + alpha*d, x\n",
    "        # ============================================================================================================ #  \n",
    "        # CGM variants\n",
    "        if iCG == \"FR\":\n",
    "            beta = (g(x).T @ g(x)) / (g(x_prev).T @ g(x_prev))\n",
    "        elif iCG == \"PR\":\n",
    "            beta = max(0, g(x).T @ (g(x) - g(x_prev)) / (g(x_prev).T @ g(x_prev)))\n",
    "        else:\n",
    "            raise TypeError(\"iCG should be FR (Fletcher-Reeves) or PR (Polak-Ribière)\")\n",
    "        # ============================================================================================================ # \n",
    "        # Restart conditions\n",
    "        if iRC > 0 and nu is None:\n",
    "            raise TypeError(f\"nu is a necessary parameter with iRC equal to {iRC}\")\n",
    "        if (iRC == 1 and k % nu == 0 or\n",
    "                iRC == 2 and g(x).T @ g(x_prev) / np.linalg.norm(g(x))**2 > nu or\n",
    "                k == 0):\n",
    "            d = -g(x)\n",
    "        else:\n",
    "            d = -g(x) + beta*d\n",
    "        # ============================================================================================================ # \n",
    "        k += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y(X, w):\n",
    "    \"\"\"Evaluates a SLNN with weigths `w` \"\"\"\n",
    "\n",
    "    return sigmoid((sigmoid(X) @ w.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_loss(w, X, ytr, p=0):\n",
    "    #return (2 * sigmoid(X) * ((y(X, w) - ytr) * y(X, w) * (1 - y(X, w))) + p*w).sum(axis=0)\n",
    "    return np.squeeze(2 * sigmoid(X.T) @ ((y(X, w) - ytr) * y(X, w) * (1 - y(X, w))) + p*w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_loss(np.full((1, 35), 2), train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_loss(wt, train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opty = BFGS(wt, lambda w: loss(w, train, ytr, 30), lambda w: g_loss(w, train, ytr, 30), 1e-6, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_show(opty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_loss(opty, train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss(opty, train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.round(np.squeeze(y(train, opty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.squeeze(ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(data):\n",
    "    if len(data) < 10:\n",
    "        return data\n",
    "    data_out = data.head(5)\n",
    "    data_out = data_out.append(data.tail(5))\n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize.linesearch import line_search\n",
    "from scipy.optimize.linesearch import line_search_BFGS\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#def nnet(Xtrain, Ytrain, lambd = 0.00, epsilon = 1.0e-06, kmax = 500, BLS_params, optimizer):\n",
    "def nnet(Xtrain, Ytrain, optimizer, epsilon = 1.0e-06, kmax = 500):\n",
    "        ### TRAIN ###\n",
    "        \n",
    "        \n",
    "        \"\"\" init rand weights \"\"\" \n",
    "        ini_weights = np.random.normal(size = 35)[None, :]\n",
    "    \n",
    "        if optimizer == \"GM\": # Steepest descent\n",
    "            \"\"\" train SLNN: \"\"\" \n",
    "            opt_w = GM(ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax)\n",
    "            num_show(opt_w)\n",
    "            print(\"Loss:\", loss(opt_w, Xtrain, Ytrain))\n",
    "            return opt_w\n",
    "\n",
    "        elif optimizer == \"CGM\": # Conjugate Gradient method\n",
    "            opt_w = CGM(ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax, \"FR\", 0)\n",
    "            num_show(opt_w)\n",
    "            print(\"Loss:\", loss(opt_w, Xtrain, Ytrain))\n",
    "\n",
    "        elif optimizer == \"BFGS\": # Quasi-Newton BFGS\n",
    "            opt_w = BFGS(ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax)\n",
    "            #opt_w, min_loss, info = scipy.optimize.fmin_l_bfgs_b(lambda w: loss(w, train, ytr), wt, fprime=(lambda w: g_loss(w, train, ytr)))\n",
    "            num_show(opt_w)\n",
    "            print(\"Loss:\", loss(opt_w, Xtrain, Ytrain))\n",
    "        \n",
    "        else:\n",
    "            print(\"Invalid optimizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnet:\n",
    "    def __init__(self, Xtrain, Ytrain):\n",
    "        self.Xtrain          = Xtrain\n",
    "        self.ini_weights    = np.random.normal(size = 35)[None, :]            \n",
    "        self.Ytrain        = Ytrain\n",
    "        \n",
    "    def accuracy_train(self, tuned_weights):\n",
    "        delta, num_samples = 0, len(self.Ytrain)\n",
    "        for i in range(num_samples):\n",
    "            if abs(np.round(y(self.Xtrain, tuned_weights)[i],2) - self.Ytrain[i]) < 1e-06: delta += 1\n",
    "        accuracy = (100/num_samples)*delta\n",
    "        print(\"Accuracy train: \", accuracy, \"%\")\n",
    "        return accuracy\n",
    "    \n",
    "    def accuracy_test(self, Xtest, Ytest, tuned_weights):\n",
    "        delta, num_samples = 0, len(Ytest)\n",
    "        for i in range(num_samples):\n",
    "            if abs(np.round(y(Xtest, tuned_weights)[i],2) - Ytest[i]) < 1e-06: delta += 1\n",
    "        accuracy = (100/num_samples)*delta\n",
    "        print(\"Accuracy test: \", accuracy, \"%\")\n",
    "        \n",
    "        if nnet.accuracy_train(self, tuned_weights)*0.25 > accuracy:\n",
    "            print(\"Possibly overfitted model!\")\n",
    "        \n",
    "    def train(self, optimizer, epsilon, kmax):\n",
    "        \"\"\" train SLNN: \"\"\" \n",
    "        if optimizer == \"GM\":\n",
    "            tuned_weights = GM(self.ini_weights, lambda w: loss(w, self.Xtrain, self.Ytrain), lambda w: g_loss(w, self.Xtrain, self.Ytrain), epsilon, kmax)\n",
    "        elif optimizer == \"CGM\":\n",
    "            tuned_weights = CGM(self.ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax, \"FR\", 0)\n",
    "        elif optimizer == \"BFGS\":\n",
    "            tuned_weights = BFGS(self.ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax)\n",
    "        else:\n",
    "            print(\"Invalid optimizer.\")\n",
    "            return self.ini_weights\n",
    "        num_show(tuned_weights)\n",
    "        print(\"Loss:\", loss(tuned_weights, self.Xtrain, self.Ytrain))\n",
    "        #nnet.accuracy_train(self, opt_w)\n",
    "        return tuned_weights\n",
    "\n",
    "    def test(self, Xtest, Ytest, tuned_weights):\n",
    "        nnet.accuracy_test(self, Xtest, Ytest, tuned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLNN:\n",
    "    def __init__(self, n = 35):\n",
    "        self.weights    = np.random.normal(size = n)[None, :]\n",
    "        self._trained = False\n",
    "        self.out = None\n",
    "        \n",
    "    def train(self, optimizer, x, y, p = 0, epsilon=10e-6, kmax = 1000):\n",
    "        if optimizer == \"GM\":\n",
    "            output = GM(self.weights, lambda w: loss(w, x, y, p), lambda w: g_loss(w, x, y, p), epsilon, kmax)\n",
    "            self.weights = output[0]\n",
    "            self.out = output[1]\n",
    "        elif optimizer == \"CGM\":\n",
    "            self.weights =  CGM(self.weights, lambda w: loss(w, x, y, p), lambda w: g_loss(w, x, y, p), epsilon, kmax, \"FR\", 0)\n",
    "        elif optimizer == \"BFGS\":\n",
    "            self.weights = BFGS(self.weights, lambda w: loss(w, x, y, p), lambda w: g_loss(w, x, y, p), epsilon, kmax)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid optimizer.\")\n",
    "        self.x, self.y, self.p = x, y, p\n",
    "        self.optimizer = optimizer\n",
    "        self._trained = True\n",
    "            \n",
    "    def predict(self, x):\n",
    "        return np.round(y(x, self.weights))\n",
    "    \n",
    "    def accuracy(self, x, y):\n",
    "        return 100 * np.sum(self.predict(x) == y) / len(y)\n",
    "    \n",
    "    def summary(self, Xte, yte):\n",
    "        if not self._trained:\n",
    "            print(\"Model is not trained yet\")\n",
    "        else:\n",
    "            print(f\"Single Layer Neural Network (SLNN)\")\n",
    "            print(\"-\"*75)\n",
    "            print(f\"Input size:\\t\\t\\t{len(np.squeeze(self.weights))}\")\n",
    "            print(f\"Output size:\\t\\t\\t1 (binary)\")\n",
    "            print(\"-\"*75)\n",
    "            print(f\"Train data:\\t\\t\\t{len(self.x)} observations\")\n",
    "            print(f\"Chosen optimization routine:\\t{self.optimizer}\")\n",
    "            print(f\"Regularization parameter:\\t{self.p}\")\n",
    "            print(f\"Loss:\\t\\t\\t\\t{loss(self.weights, self.x, self.y, self.p)[0]}\")\n",
    "            print(f\"Training accuracy:\\t\\t{self.accuracy(self.x, self.y)}%\")\n",
    "            print(f\"Test accuracy:\\t\\t\\t{self.accuracy(Xte, yte)}%\")\n",
    "            print(\"-\"*75)\n",
    "            print(\"Gradient: \\n\", g_loss(self.weights, self.x, self.y, self.p))\n",
    "            print(\"-\"*75)\n",
    "            num_show(self.weights)\n",
    "            return print_result(self.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Layer Neural Network (SLNN)\n",
      "---------------------------------------------------------------------------\n",
      "Input size:\t\t\t35\n",
      "Output size:\t\t\t1 (binary)\n",
      "---------------------------------------------------------------------------\n",
      "Train data:\t\t\t500 observations\n",
      "Chosen optimization routine:\tGM\n",
      "Regularization parameter:\t0\n",
      "Loss:\t\t\t\t13.641830007634379\n",
      "Training accuracy:\t\t98.4%\n",
      "Test accuracy:\t\t\t94.74%\n",
      "---------------------------------------------------------------------------\n",
      "Gradient: \n",
      " [-0.13423706  0.04281285 -0.28659512  0.06347185 -0.11487062  0.00674288\n",
      " -0.41977516 -0.39548342 -0.08993109 -0.00440703  0.1137969  -0.10229214\n",
      " -0.35736398 -0.06308361 -0.0280074   0.15288279 -0.13129653 -0.39362591\n",
      "  0.01724462 -0.08320167 -0.12775101 -0.03663251 -0.31644884 -0.05009252\n",
      "  0.01348525 -0.0320495  -0.0525353  -0.36035881  0.1057012   0.01148359\n",
      " -0.01362395 -0.24500897 -0.35242343 -0.45403212 -0.16463631]\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>f(x)</th>\n",
       "      <th>||g(x)||</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>198.051930</td>\n",
       "      <td>105.646819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>164.418085</td>\n",
       "      <td>31.970803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004113</td>\n",
       "      <td>162.142421</td>\n",
       "      <td>26.607511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006429</td>\n",
       "      <td>159.803263</td>\n",
       "      <td>34.621168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003903</td>\n",
       "      <td>157.597897</td>\n",
       "      <td>28.498137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.007587</td>\n",
       "      <td>13.678495</td>\n",
       "      <td>1.236342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.012044</td>\n",
       "      <td>13.669384</td>\n",
       "      <td>1.557740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.007509</td>\n",
       "      <td>13.660212</td>\n",
       "      <td>1.218828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.012349</td>\n",
       "      <td>13.651002</td>\n",
       "      <td>1.560980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.007559</td>\n",
       "      <td>13.641830</td>\n",
       "      <td>1.225461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         alpha        f(x)    ||g(x)||\n",
       "0          NaN  198.051930  105.646819\n",
       "1     0.003906  164.418085   31.970803\n",
       "2     0.004113  162.142421   26.607511\n",
       "3     0.006429  159.803263   34.621168\n",
       "4     0.003903  157.597897   28.498137\n",
       "996   0.007587   13.678495    1.236342\n",
       "997   0.012044   13.669384    1.557740\n",
       "998   0.007509   13.660212    1.218828\n",
       "999   0.012349   13.651002    1.560980\n",
       "1000  0.007559   13.641830    1.225461"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0.3)\n",
    "slnnGM = SLNN()\n",
    "slnnGM.train(\"GM\", train, ytr)\n",
    "slnnGM.summary(test, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-bfed347d73a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnnetGM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnetGM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0e-06\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnnetGM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-e209e57d4333>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, optimizer, epsilon, kmax)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid optimizer.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mini_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mnum_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuned_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuned_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#nnet.accuracy_train(self, opt_w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/SLNN/main.py\u001b[0m in \u001b[0;36mnum_show\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnum_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnetGM = nnet(train, ytr)\n",
    "tuning = nnetGM.train(\"GM\", 1.0e-06, kmax = 500)\n",
    "nnetGM.test(test, yte, tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnetCGM = nnet(train, ytr)\n",
    "tuning = nnetGM.train(\"CGM\", 1.0e-06, kmax = 500)\n",
    "nnetCGM.test(test, yte, tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnetBFGS = nnet(train, ytr)\n",
    "tuning = nnetGM.train(\"BFGS\", 1.0e-06, kmax = 500)\n",
    "nnetBFGS.test(test, yte, tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "#nnet(train, ytr, \"BFGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnet(train, ytr, \"CGM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1,3,5,7,9], 0.5, 0)\n",
    "nnet(train, ytr, \"GM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [0,2,4,6,8], 0.5, 0)\n",
    "nnet(train, ytr, \"GM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [0,2,4,6,8], 0.5, 0)\n",
    "nnet(train, ytr, \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnet(train, ytr, \"BFGS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MATLAB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mXtr = np.array([\n",
    "    [1, 1, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "]).T\n",
    "mytr = np.array([[0, 0, 1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06814337, 0.05493228, 0.04590823])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss(np.array([[2, 2, 2]]), mXtr, mytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
