{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_show(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize.linesearch import line_search\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = np.random.normal(size = 35, scale = 0.1)[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = minimize(lambda w: loss(w, train, ytr), wt, method = 'BFGS')\n",
    "opt_w = opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_show(opt_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize.linesearch import line_search_BFGS\n",
    "#from optinpy.optinpy.linesearch import interp23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GM(x, f, g, eps, kmax):\n",
    "    k = 0\n",
    "    almax = 1\n",
    "    while np.linalg.norm(g(x)) > eps and k < kmax:\n",
    "        d = -g(x)\n",
    "        if k != 0:\n",
    "            almax = np.squeeze(2 * (f(x) - f(x_prev)) / (g(x).T @ d))\n",
    "        alpha, iout = linesearch(f, g, x, d, alpham = almax, c1 = 0.01, c2 = 0.45, maxiter = 500, eps = 10e-6)\n",
    "        x_prev = x\n",
    "        x = x + alpha*d\n",
    "        k += 1\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp23(lambda w: np.squeeze(loss(w, train, ytr)), np.squeeze(wt), -g_loss(wt, train, ytr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ls import linesearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFGS(x, f, g, eps, kmax):\n",
    "    H = I = np.identity(len(g(x)))\n",
    "    k = 0\n",
    "    almax = 1\n",
    "    while np.linalg.norm(g(x)) > eps and k < kmax:\n",
    "        d = -H @ g(x)\n",
    "        if k != 0:\n",
    "            almax = np.squeeze(2 * (f(x) - f(x_prev)) / (g(x).T @ d))\n",
    "            #almax = old_al * ((old_g.T) @ old_d) / (g(x).T @ d)\n",
    "        print(\"almax: \", almax)\n",
    "        alpha, iout = linesearch(f, g, x, d, alpham = almax, c1 = 0.01, c2 = 0.45, maxiter = 50, eps = 10e-6)\n",
    "        #alpha, *_ = line_search_BFGS(f, lambda x: g(x).T, x, d.T, c1 = 0.01, old_fval=1)\n",
    "        print(\" alpha: \", alpha)\n",
    "        if alpha == 0:\n",
    "            return x\n",
    "        old_g = g(x)\n",
    "        old_d = d\n",
    "        old_al = alpha\n",
    "        x, x_prev = x + alpha*d, x\n",
    "        s = x - x_prev\n",
    "        y = g(x) - g(x_prev)\n",
    "        y = y[None, :]\n",
    "        rho = 1 / ((y).T @ s)\n",
    "        H = (I - rho * s @ y.T) @ H @ (I - rho * y @ (s.T)) + rho * s @ s.T\n",
    "        k += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CGM(x, f, g, eps, kmax, iCG, iRC):\n",
    "    d = -g(x)\n",
    "    k = 0\n",
    "    while np.linalg.norm(g(x)) > eps and k < kmax:\n",
    "        alpha, iout = linesearch(f, g, x, d, 50, c1 = 0.01, c2 = 0.45, maxiter = 500, eps = 10e-6)\n",
    "        x, x_prev = x + alpha*d, x\n",
    "        # ============================================================================================================ #  \n",
    "        # CGM variants\n",
    "        if iCG == \"FR\":\n",
    "            beta = (g(x).T @ g(x)) / (g(x_prev).T @ g(x_prev))\n",
    "        elif iCG == \"PR\":\n",
    "            beta = max(0, g(x).T @ (g(x) - g(x_prev)) / (g(x_prev).T @ g(x_prev)))\n",
    "        else:\n",
    "            raise TypeError(\"iCG should be FR (Fletcher-Reeves) or PR (Polak-Ribière)\")\n",
    "        # ============================================================================================================ # \n",
    "        # Restart conditions\n",
    "        if iRC > 0 and nu is None:\n",
    "            raise TypeError(f\"nu is a necessary parameter with iRC equal to {iRC}\")\n",
    "        if (iRC == 1 and k % nu == 0 or\n",
    "                iRC == 2 and g(x).T @ g(x_prev) / np.linalg.norm(g(x))**2 > nu or\n",
    "                k == 0):\n",
    "            d = -g(x)\n",
    "        else:\n",
    "            d = -g(x) + beta*d\n",
    "        # ============================================================================================================ # \n",
    "        k += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y(X, w):\n",
    "    \"\"\"Evaluates a SLNN with weigths `w` \"\"\"\n",
    "\n",
    "    return sigmoid((sigmoid(X) @ w.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_loss(w, X, ytr, p=0):\n",
    "    #return (2 * sigmoid(X) * ((y(X, w) - ytr) * y(X, w) * (1 - y(X, w))) + p*w).sum(axis=0)\n",
    "    return np.squeeze(2 * sigmoid(X.T) @ ((y(X, w) - ytr) * y(X, w) * (1 - y(X, w))) + p*w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss(np.full((1, 35), 2), train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.53213305,  -4.64411024, -10.85372445,  -2.03687056,\n",
       "        -5.33558985,  -4.86779169, -13.63290748, -16.24014716,\n",
       "        -6.01259679,  -5.31158902,  -2.78441564,  -6.7558145 ,\n",
       "       -15.57266839,  -5.34511802,  -5.31158902,  -4.30374476,\n",
       "        -5.37489972, -13.78398627,  -3.21665815,  -5.78458839,\n",
       "        -3.9108117 ,  -6.01259679, -14.48967294,  -6.01259679,\n",
       "        -2.3766483 ,  -4.24626206,  -7.08351553, -16.24014716,\n",
       "        -6.01259679,  -3.78734478,  -7.08351553, -12.48810238,\n",
       "       -12.48810238, -11.0774059 ,  -7.30719697])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss(wt, train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "almax:  1\n",
      " alpha:  0.0078125\n",
      "almax:  6.614779693841252e-10\n",
      " alpha:  6.614779693841252e-10\n",
      "almax:  9.69665699261787e-15\n",
      " alpha:  9.69665699261787e-15\n",
      "almax:  -2.3713326086513976e-21\n",
      " alpha:  -2.3713326086513976e-21\n",
      "almax:  -7.512756949587103e-27\n",
      " alpha:  -7.512756949587103e-27\n",
      "almax:  -2.7988320596715026e-33\n",
      " alpha:  -2.7988320596715026e-33\n",
      "almax:  -1.3127167812830097e-39\n",
      " alpha:  -1.3127167812830097e-39\n",
      "almax:  -7.269178162392965e-46\n",
      " alpha:  -7.269178162392965e-46\n",
      "almax:  -4.146224011991898e-52\n",
      " alpha:  -4.146224011991898e-52\n",
      "almax:  -2.3892114051862034e-58\n",
      " alpha:  -2.3892114051862034e-58\n",
      "almax:  -1.4126383146829818e-64\n",
      " alpha:  -1.4126383146829818e-64\n",
      "almax:  -8.180797859029074e-71\n",
      " alpha:  -8.180797859029074e-71\n",
      "almax:  -4.876897336101842e-77\n",
      " alpha:  -4.876897336101842e-77\n",
      "almax:  -2.823078640836878e-83\n",
      " alpha:  -2.823078640836878e-83\n",
      "almax:  -1.6857762054539825e-89\n",
      " alpha:  -1.6857762054539825e-89\n",
      "almax:  -9.747450546476394e-96\n",
      " alpha:  -9.747450546476394e-96\n",
      "almax:  -5.820459640205253e-102\n",
      " alpha:  -5.820459640205253e-102\n",
      "almax:  -3.3617253753582397e-108\n",
      " alpha:  -3.3617253753582397e-108\n",
      "almax:  -2.0063773745847102e-114\n",
      " alpha:  -2.0063773745847102e-114\n",
      "almax:  -1.1575880440483362e-120\n",
      " alpha:  -1.1575880440483362e-120\n",
      "almax:  -6.904429932482416e-127\n",
      " alpha:  -6.904429932482416e-127\n",
      "almax:  -3.9793922063586394e-133\n",
      " alpha:  -3.9793922063586394e-133\n",
      "almax:  -2.371888436702658e-139\n",
      " alpha:  -2.371888436702658e-139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibrarmalik/Documents/UPC/OM/Part 1/SLNN/main.py:92: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "almax:  -1.3656316697462177e-145\n",
      " alpha:  -1.3656316697462177e-145\n",
      "almax:  -8.134059407216972e-152\n",
      " alpha:  -8.134059407216972e-152\n",
      "almax:  -4.678387787306947e-158\n",
      " alpha:  -4.678387787306947e-158\n",
      "almax:  -2.784598121585543e-164\n",
      " alpha:  -2.784598121585543e-164\n",
      "almax:  -1.5999212286936645e-170\n",
      " alpha:  -1.5999212286936645e-170\n",
      "almax:  -9.516011425893702e-177\n",
      " alpha:  -9.516011425893702e-177\n",
      "almax:  -5.461793664624957e-183\n",
      " alpha:  -5.461793664624957e-183\n",
      "almax:  -3.2462320998604345e-189\n",
      " alpha:  -3.2462320998604345e-189\n",
      "almax:  -1.8612340873455198e-195\n",
      " alpha:  -1.8612340873455198e-195\n",
      "almax:  -1.1054298787462612e-201\n",
      " alpha:  -1.1054298787462612e-201\n",
      "almax:  -6.331264599703833e-208\n",
      " alpha:  -6.331264599703833e-208\n",
      "almax:  -3.757548698217085e-214\n",
      " alpha:  -3.757548698217085e-214\n",
      "almax:  -2.149801732947782e-220\n",
      " alpha:  -2.149801732947782e-220\n",
      "almax:  -1.2749540911341482e-226\n",
      " alpha:  -1.2749540911341482e-226\n",
      "almax:  -7.286509243961302e-233\n",
      " alpha:  -7.286509243961302e-233\n",
      "almax:  -4.3181295519806886e-239\n",
      " alpha:  -4.3181295519806886e-239\n",
      "almax:  -2.4651789607962254e-245\n",
      " alpha:  -2.4651789607962254e-245\n",
      "almax:  -1.4598311404302914e-251\n",
      " alpha:  -1.4598311404302914e-251\n",
      "almax:  -8.324915277519635e-258\n",
      " alpha:  -8.324915277519635e-258\n",
      "almax:  -4.926177073761258e-264\n",
      " alpha:  -4.926177073761258e-264\n",
      "almax:  -2.806132725660679e-270\n",
      " alpha:  -2.806132725660679e-270\n",
      "almax:  -1.6592522667886094e-276\n",
      " alpha:  -1.6592522667886094e-276\n",
      "almax:  -9.441220745260158e-283\n",
      " alpha:  -9.441220745260158e-283\n",
      "almax:  -0.0\n",
      " alpha:  -0.0\n"
     ]
    }
   ],
   "source": [
    "opty = BFGS(wt, lambda w: loss(w, train, ytr, 30), lambda w: g_loss(w, train, ytr, 30), 1e-6, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.93071739e+08, -6.99312386e+08, -8.87125910e+08,\n",
       "        -7.02038395e+08, -6.93977759e+08, -6.98040254e+08,\n",
       "        -8.28956717e+08, -8.01332238e+08, -6.92623101e+08,\n",
       "        -6.97816383e+08, -6.98112579e+08, -6.92620538e+08,\n",
       "        -8.15974631e+08, -6.93166039e+08, -6.97822567e+08,\n",
       "        -6.94071199e+08, -6.94059874e+08, -8.49881131e+08,\n",
       "        -6.99222660e+08, -6.94097796e+08, -6.95308141e+08,\n",
       "        -6.92622581e+08, -8.39069113e+08, -6.92622147e+08,\n",
       "        -6.99495963e+08, -6.96632805e+08, -6.93022258e+08,\n",
       "        -8.01263523e+08, -6.92621562e+08, -6.98052944e+08,\n",
       "        -6.93027855e+08, -8.74894507e+08, -8.74911883e+08,\n",
       "        -8.81735061e+08, -6.92610189e+08]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_show(opty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss(opty, train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([250.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(opty, train, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.squeeze(y(train, opty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize.linesearch import line_search\n",
    "from scipy.optimize.linesearch import line_search_BFGS\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#def nnet(Xtrain, Ytrain, lambd = 0.00, epsilon = 1.0e-06, kmax = 500, BLS_params, optimizer):\n",
    "def nnet(Xtrain, Ytrain, optimizer, epsilon = 1.0e-06, kmax = 500):\n",
    "        ### TRAIN ###\n",
    "        \n",
    "        \n",
    "        \"\"\" init rand weights \"\"\" \n",
    "        ini_weights = np.random.normal(size = 35)[None, :]\n",
    "    \n",
    "        if optimizer == \"GM\": # Steepest descent\n",
    "            \"\"\" train SLNN: \"\"\" \n",
    "            opt_w = GM(ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax)\n",
    "            num_show(opt_w)\n",
    "            print(\"Loss:\", loss(opt_w, Xtrain, Ytrain))\n",
    "            return opt_w\n",
    "\n",
    "        elif optimizer == \"CGM\": # Conjugate Gradient method\n",
    "            opt_w = CGM(ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax, \"FR\", 0)\n",
    "            num_show(opt_w)\n",
    "            print(\"Loss:\", loss(opt_w, Xtrain, Ytrain))\n",
    "\n",
    "        elif optimizer == \"BFGS\": # Quasi-Newton BFGS\n",
    "            opt_w = BFGS(ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax)\n",
    "            #opt_w, min_loss, info = scipy.optimize.fmin_l_bfgs_b(lambda w: loss(w, train, ytr), wt, fprime=(lambda w: g_loss(w, train, ytr)))\n",
    "            num_show(opt_w)\n",
    "            print(\"Loss:\", loss(opt_w, Xtrain, Ytrain))\n",
    "        \n",
    "        else:\n",
    "            print(\"Invalid optimizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnet:\n",
    "    def __init__(self, Xtrain, Ytrain):\n",
    "        self.Xtrain          = Xtrain\n",
    "        self.ini_weights    = np.random.normal(size = 35)[None, :]            \n",
    "        self.Ytrain        = Ytrain\n",
    "        \n",
    "    def accuracy_train(self, tuned_weights):\n",
    "        delta, num_samples = 0, len(self.Ytrain)\n",
    "        for i in range(num_samples):\n",
    "            if abs(np.round(y(self.Xtrain, tuned_weights)[i],2) - self.Ytrain[i]) < 1e-06: delta += 1\n",
    "        accuracy = (100/num_samples)*delta\n",
    "        print(\"Accuracy train: \", accuracy, \"%\")\n",
    "        return accuracy\n",
    "    \n",
    "    def accuracy_test(self, Xtest, Ytest, tuned_weights):\n",
    "        delta, num_samples = 0, len(Ytest)\n",
    "        for i in range(num_samples):\n",
    "            if abs(np.round(y(Xtest, tuned_weights)[i],2) - Ytest[i]) < 1e-06: delta += 1\n",
    "        accuracy = (100/num_samples)*delta\n",
    "        print(\"Accuracy test: \", accuracy, \"%\")\n",
    "        \n",
    "        if nnet.accuracy_train(self, tuned_weights)*0.25 > accuracy:\n",
    "            print(\"Possibly overfitted model!\")\n",
    "        \n",
    "    def train(self, optimizer, epsilon, kmax):\n",
    "        \"\"\" train SLNN: \"\"\" \n",
    "        if optimizer == \"GM\":\n",
    "            tuned_weights = GM(self.ini_weights, lambda w: loss(w, self.Xtrain, self.Ytrain), lambda w: g_loss(w, self.Xtrain, self.Ytrain), epsilon, kmax)\n",
    "        elif optimizer == \"CGM\":\n",
    "            tuned_weights = CGM(self.ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax, \"FR\", 0)\n",
    "        elif optimizer == \"BFGS\":\n",
    "            tuned_weights = BFGS(self.ini_weights, lambda w: loss(w, train, ytr), lambda w: g_loss(w, train, ytr), epsilon, kmax)\n",
    "        else:\n",
    "            print(\"Invalid optimizer.\")\n",
    "            return self.ini_weights\n",
    "        num_show(tuned_weights)\n",
    "        print(\"Loss:\", loss(tuned_weights, self.Xtrain, self.Ytrain))\n",
    "        #nnet.accuracy_train(self, opt_w)\n",
    "        return tuned_weights\n",
    "\n",
    "    def test(self, Xtest, Ytest, tuned_weights):\n",
    "        nnet.accuracy_test(self, Xtest, Ytest, tuned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLNN:\n",
    "    def __init__(self, n = 35):\n",
    "        self.weights    = np.random.normal(size = n)[None, :]\n",
    "        self._trained = False\n",
    "        \n",
    "    def train(self, optimizer, x, y, p = 0, epsilon=10e-6, kmax = 500):\n",
    "        if optimizer == \"GM\":\n",
    "            self.weights =   GM(self.weights, lambda w: loss(w, x, y, p), lambda w: g_loss(w, x, y, p), epsilon, kmax)\n",
    "        elif optimizer == \"CGM\":\n",
    "            self.weights =  CGM(self.weights, lambda w: loss(w, x, y, p), lambda w: g_loss(w, x, y, p), epsilon, kmax, \"FR\", 0)\n",
    "        elif optimizer == \"BFGS\":\n",
    "            self.weights = BFGS(self.weights, lambda w: loss(w, x, y, p), lambda w: g_loss(w, x, y, p), epsilon, kmax)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid optimizer.\")\n",
    "        self.x, self.y, self.p = x, y, p\n",
    "        self.optimizer = optimizer\n",
    "        self._trained = True\n",
    "            \n",
    "    def predict(self, x):\n",
    "        return np.round(y(x, self.weights))\n",
    "    \n",
    "    def accuracy(self, x, y):\n",
    "        return 100 * np.sum(self.predict(x) == y) / len(y)\n",
    "    \n",
    "    def summary(self, Xte, yte):\n",
    "        if not self._trained:\n",
    "            print(\"Model is not trained yet\")\n",
    "        else:\n",
    "            print(f\"SLNN of {len(np.squeeze(self.weights))} neurons\")\n",
    "            print(f\"Train data: {len(self.x)} observations\")\n",
    "            print(f\"Chosen optimization routine: {self.optimizer}\")\n",
    "            print(f\"Regularization parameter: {self.p}\")\n",
    "            print(\"Loss: \", loss(self.weights, self.x, self.y, self.p))\n",
    "            print(f\"Training accuracy: {self.accuracy(self.x, self.y)}%\")\n",
    "            print(f\"Test accuracy: {self.accuracy(Xte, yte)}%\")\n",
    "            print(\"Gradient: \\n\", g_loss(self.weights, self.x, self.y, self.p))\n",
    "            num_show(self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "almax:  1\n",
      " alpha:  0.0029296875\n",
      "almax:  1.397904265101629e-05\n",
      " alpha:  3.4947606627540726e-06\n",
      "SLNN of 35 neurons\n",
      "Train data: 500 observations\n",
      "Chosen optimization routine: BFGS\n",
      "Regularization parameter: 0\n",
      "Loss:  [250.]\n",
      "Training accuracy: 50.0%\n",
      "Test accuracy: 90.0%\n",
      "Gradient: \n",
      " [-2.72615035e-12 -3.71325781e-12 -3.73754202e-12 -3.74945139e-12\n",
      " -2.79852898e-12 -3.67467902e-12 -2.73868631e-12 -2.71741628e-12\n",
      " -2.75991585e-12 -3.71120295e-12 -3.81556256e-12 -2.76323664e-12\n",
      " -2.76182008e-12 -2.78758695e-12 -3.65894200e-12 -2.79252569e-12\n",
      " -3.71934211e-12 -3.71718432e-12 -3.69898511e-12 -2.74234423e-12\n",
      " -3.68775184e-12 -2.77516863e-12 -2.76391449e-12 -2.79817440e-12\n",
      " -3.79767828e-12 -3.73751699e-12 -2.78855829e-12 -2.74296637e-12\n",
      " -2.80600293e-12 -3.75293283e-12 -2.75925074e-12 -3.78306433e-12\n",
      " -3.70463196e-12 -3.70616315e-12 -2.74734174e-12]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [8], 0.5, 0.1)\n",
    "slnnGM = SLNN()\n",
    "slnnGM.train(\"BFGS\", train, ytr)\n",
    "slnnGM.summary(test, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnetGM = nnet(train, ytr)\n",
    "tuning = nnetGM.train(\"GM\", 1.0e-06, kmax = 500)\n",
    "nnetGM.test(test, yte, tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnetCGM = nnet(train, ytr)\n",
    "tuning = nnetGM.train(\"CGM\", 1.0e-06, kmax = 500)\n",
    "nnetCGM.test(test, yte, tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnetBFGS = nnet(train, ytr)\n",
    "tuning = nnetGM.train(\"BFGS\", 1.0e-06, kmax = 500)\n",
    "nnetBFGS.test(test, yte, tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "#nnet(train, ytr, \"BFGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnet(train, ytr, \"CGM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1,3,5,7,9], 0.5, 0)\n",
    "nnet(train, ytr, \"GM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [0,2,4,6,8], 0.5, 0)\n",
    "nnet(train, ytr, \"GM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [0,2,4,6,8], 0.5, 0)\n",
    "nnet(train, ytr, \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, ytr, yte = gen_data(123456, 500, [1], 0.5, 0)\n",
    "nnet(train, ytr, \"BFGS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MATLAB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mXtr = np.array([\n",
    "    [1, 1, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "]).T\n",
    "mytr = np.array([[0, 0, 1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06814337, 0.05493228, 0.04590823])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss(np.array([[2, 2, 2]]), mXtr, mytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
